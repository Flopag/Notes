# Q4 : Bias-variance tradeoff

>**Bias-variance tradeoff**: bias-variance decomposition (derivation and interpretation of the different terms, link with over- and under-fitting), parameters that influence bias and variance, bias and variance estimation.

## Bias-variance decomposition

Bias-variance decomposition is used to find the best learning algorithm by minimizing:

$$E=E_{LS}\{E_Y\{(y-\hat y)^2\}\}$$
The decomposition is:

$$E = var_y\{y\}+bias^2+var_{LS}\{\hat y\}$$

where:
- $var_y\{y\}$ is the residual error -> the minimal attainable error
- $biasÂ² = (E_y\{y\} - E_{LS}\{\hat y\})^2$ -> the difference between the average model ($E_{LS}\{\hat y\}$) and the Bayes model ($E_y\{y\}$)
- $var_{LS}\{\hat y\}$ is the estimation variance

Extension to a problem with inputs :

$$E = noise(x)+bias^2(x)+var(x)$$

where:
- $noise(x) = E_{Y|x}\{(y-h_B(x))^2\}$ -> quantifies how much $y$ varies from $h_B(x) = E_{y|x}\{y\}$
- $bias^2(x)=(h_B(x)-E_{LS}\{\hat y(x)\})^2$ -> measures the error between the Bayes model and the average model
- $variance(x)=E_{LS}\{(\hat y(x)-E_{LS}\{\hat y(x)\})^2\}$ -> quantifies how much $\hat y(x)$ varies from one learning sample to another

### Link with over- and under-fitting

- Low variance and high bias leads to under-fitting
- Low bias and high variance leads to over-fitting

## Parameters that influence bias and variance

The bias is a systematic error component, which is independent of the learning sample. Rather, it depends on the learning algorithm

The variance is the error due to the variability of the model with respect to the learning sample randomness

- The bias is a decreasing function of the complexity
- The variance is an increasing function of the complexity
(for k-NN, this is the inverse)

![](attachments/Pasted%20image%2020231107164122.png)

Variance increases with noise while bias remains mainly unaffected (logic because independent of LS)

![](attachments/Pasted%20image%2020231107164403.png)

At fixed model complexity, bias remains constant and variance decreases with the learning sample size

![](attachments/Pasted%20image%2020231107164456.png)

When the complexity of the model is dependent on the learning sample size, both bias and variance decrease with the learning sample size

![](attachments/Pasted%20image%2020231107164620.png)

## Bias and variance estimation